# --- 主工作目录 ---
work_dir: ./work_dir/dhg14_28_sdtgru_14class_s1_dim128 # 修改工作目录名以反映配置变化

# --- 指定要融合训练的模态 ---
modalities: ['joint', 'bone', 'joint_motion']
base_channel: 3

# --- 数据加载器配置 ---
feeder: feeders.feeder_dhg14_28.Feeder
train_feeder_args:
  root_dir: 'data/DHG14-28/DHG14-28_preprocessed_npy'
  original_sample_list_root_dir: 'data/DHG14-28/DHG14-28_sample_json'
  split: 'train'
  subject_idx: 1
  label_type: 'label_14'
  max_len: 150
  data_path: 'joint,bone,joint_motion'
  base_channel: 3
  repeat: 1
  random_choose: true
  center_joint_idx: 0
  # num_classes: 14 # Feeder 会自行推断或从 model_args 获取

test_feeder_args:
  root_dir: 'data/DHG14-28/DHG14-28_preprocessed_npy'
  original_sample_list_root_dir: 'data/DHG14-28/DHG14-28_sample_json'
  split: 'val'
  subject_idx: 1
  label_type: 'label_14'
  max_len: 150
  data_path: 'joint,bone,joint_motion'
  base_channel: 3
  repeat: 1
  random_choose: false
  center_joint_idx: 0
  # num_classes: 14

# --- 模型配置 (SDT-GRU，降低维度) ---
model: model.SDT_GRUs_Gesture.SDT_GRU_Classifier
model_args:
  # num_input_dim: 由 main.py 计算
  num_nodes: 22
  num_classes: 14
  max_seq_len: 150
  # --- 降低维度的 SDT-GRU 模型参数 ---
  num_rnn_layers: 2         # 可以考虑先降为 1
  num_rnn_units: 128        # <<<--- 核心修改：降低到 128
  n_heads: 8                # 可以考虑降为 4
  ffn_dim: 256              # <<<--- 配套修改：num_rnn_units * 2
  st_layers: 1              # <<<--- 配套修改：减少空间注意力层数
  st_dropout_rate: 0.15     # 可以适当调整
  rnn_dropout_rate: 0.15    # 可以适当调整
  classifier_dropout: 0.3   # 可以适当调整
  use_temporal_attn: true   # 保持开启，如果速度仍然是首要问题，可以设为 false
  num_temporal_layers: 1
  temporal_n_heads: 4       # <<<--- 配套修改：减少时间注意力头数
  temporal_ffn_dim: 512     # <<<--- 配套修改：num_rnn_units (128) * 4
  temporal_dropout_rate: 0.15 # 可以适当调整
  use_gap: true
  classifier_hidden_dim: 64 # 或者考虑 128/2 = 64
  use_conv_proj: true       # 如果速度是极致追求，可设为 false
  conv_kernel_size: 3
  qkv_bias: false
  output_attention: false

# --- 优化器与学习率 ---
optimizer: SGD
base_lr: 0.05             # <<<--- 对于 SGD 和 warmup，目标学习率可以设置稍高一些
weight_decay: 0.0002
nesterov: True

# --- 学习率调度器 ---
lr_scheduler: cosine      # <<<--- 强烈建议使用 cosine 调度器配合 warmup
# step: [80, 120]         # cosine 调度器不需要 step
# lr_decay_rate: 0.1      # cosine 调度器不需要 lr_decay_rate
min_lr: 0.00001           # 余弦退火的最小学习率
warm_up_epoch: 5          # <<<--- 对于 iteration-level warmup，5 个 epoch 通常足够
warmup_lr: 0.00001        # warmup 开始时的学习率
warmup_prefix: true       # 确保 Processor 中 timm scheduler 的 warmup_prefix 生效

# --- 训练与测试流程配置 ---
batch_size: 170           # <<<--- 提高训练批次大小
test_batch_size: 256      # <<<--- 测试批次大小也可以相应提高
num_epoch: 150
num_worker: 8             # 保持或适当调整 (4-8)
loss_type: CE

# --- 梯度裁剪 ---
grad_clip: false

# --- 日志与保存 ---
log_interval: 50
eval_interval: 1
save_interval: 0
save_epoch: 0
print_log: true
save_score: true
show_topk: [1]

# --- 早停 ---
early_stop_patience: 0

# --- 设备和种子 ---
device: [0]
seed: 1