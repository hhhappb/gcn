awork_dir: ./work_dir/nw-ucla/2  # 为这个实验设置新的工作目录
# config: (这个通常由命令行指定，YAML内部不需要再写config指向自身)
phase: train
seed: 1
device: [0 , 1]

# --- 数据设置 ---
feeder: feeders.feeder_ucla.Feeder # 指向你的 v1.7 feeder_ucla.py
modalities: ['joint']      # <<< 关键：顶层指定为单模态 bone
base_channel: 3           # <<< 关键：单模态 bone 的基础通道数

train_feeder_args:
  root_dir: 'data/nw-ucla/all_sqe/all_sqe/' # <<< 关键：Feeder 需要的JSON数据根目录，确保路径正确
  split: 'train'                            # <<< 关键：告诉Feeder这是训练集
  data_path: 'joint'                         # <<< 关键：告诉Feeder v1.7 加载并处理 'bone' 模态
  num_classes: 10
  num_nodes: 20 
  max_len: 52                             # <<< 关键：序列长度
  repeat: 5
  random_choose: true                     # v1.7 Feeder 支持
  apply_rand_view_transform: true         # v1.7 Feeder 支持
  rand_view_rotation_range: [-60, 60]
  rand_view_scale_range: [0.5, 1.5]     # 与成功实验一致
  apply_random_flipping: true           # v1.7 Feeder 支持
  normalization: false                   # 与成功实验一致, v1.7 Feeder 支持

test_feeder_args:
  root_dir: 'data/nw-ucla/all_sqe/all_sqe/' # <<< 关键
  split: 'val'                              # <<< 关键
  data_path: 'joint'                         # <<< 关键
  num_classes: 10
  num_nodes: 20 
  max_len: 52                               # <<< 关键
  repeat: 1
  normalization: false                     
  random_choose: false
  apply_rand_view_transform: false
  add_gaussian_noise: false             

# --- 模型设置 ---
model: model.SDT_GRUs_Gesture.SDT_BiGRU_Classifier
model_args:
  # --- 基础配置 ---
  num_nodes: 20
  num_classes: 10
  max_seq_len: 52
  bidirectional: true

  # --- 输入嵌入和空间处理维度 ---
  embedding_dim: 128      # <<< 新增/修改: 空间注意力处理的特征维度
                          #     可以与之前的 num_rnn_units 保持一致

  # --- 主要时间序列模型配置 ---
  temporal_model_type: 'gru'  # <<< 新增: 'gru' 或 'transformer'
  temporal_hidden_dim: 128    # <<< 新增: GRU的hidden_size或Transformer的d_model
  num_temporal_main_layers: 2 # <<< 新增: 主要时间模型的层数
  bidirectional_time_gru: true # <<< 新增: 控制主GRU是否双向 (如果 temporal_model_type 是 'gru')
  temporal_main_dropout: 0.15  # <<< 新增: 主时间模型的dropout率
  use_time_pos_enc: true           # <<< 新增/确认: 是否为时间序列模型添加位置编码

  # +++ MultiScaleTemporalModeling 配置 +++
  use_multiscale_temporal_modeling: true
  multiscale_temporal_args:
    short_term_kernels: [1, 3, 5]
    long_term_kernels: [9]
    long_term_dilations: [5]
    conv_out_channels_ratio: 0.3
    fusion_hidden_dim_ratio: 0.3
    dropout_rate: 0.2

  # -- 空间注意力参数 (与成功实验一致) --
  sa_local_st_layers: 1
  sa_local_n_heads: 8
  sa_local_ffn_dim: 256
  sa_local_dropout_rate: 0.1
  sa_local_qkv_bias: false
  sa_local_use_conv_proj: true
  sa_local_conv_kernel_size: 3

  sa_global_st_layers: 1
  sa_global_n_heads: 8
  sa_global_ffn_dim: 256
  sa_global_dropout_rate: 0.15
  sa_global_qkv_bias: false
  sa_global_use_conv_proj: true
  sa_global_conv_kernel_size: 7
  sa_global_use_global_spatial_bias: true

  local_adj_k_hop: 1
  spatial_fusion_type: 'dynamic_gate'
  spatial_fusion_gate_hidden_dim: 32

  # --- 时间注意力 (Temporal Attention after GRUs) 配置 ---
  use_temporal_attn: true
  num_temporal_layers: 2   # 与成功实验一致
  temporal_n_heads: 8
  temporal_ffn_dim: 512
  temporal_dropout_rate: 0.1
  
  classifier_hidden_dim: 64
  classifier_dropout: 0.4
  output_attention: false

# --- 训练策略 ---
optimizer: AdamW
base_lr: 0.002
weight_decay: 0.02
grad_clip: true
grad_max: 10.0

lr_scheduler: multistep
step: [60]
lr_decay_rate: 0.1
warm_up_epoch: 5


num_epoch: 80
start_epoch: 0
batch_size: 128
test_batch_size: 128
num_worker: 12

loss_type: SmoothCE
early_stop_patience: 0

# --- 日志与保存 ---
log_interval: 0
eval_interval: 1
save_interval: 0
save_epoch: 0
print_log: true
save_score: true
show_topk: [1]